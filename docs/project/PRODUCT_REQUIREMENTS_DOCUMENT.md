# LLM-Cache 产品需求文档 (PRD)

**文档版本**: 1.0
**状态**: 草稿
**作者**: PM_Pro (AI) & [您的名字]

---

## 1. 引言

### 1.1. 项目背景
随着大型语言模型（LLM）在企业应用中的普及，API 调用成本和响应延迟成为两大核心痛点。尤其在知识问答、内容生成、RAG 等高频交互场景下，重复或相似的查询导致了大量的资源浪费。本项目旨在通过构建一个高性能的语义缓存层，有效解决上述问题。

### 1.2. LLM-Cache 是什么？
LLM-Cache 是一个基于 Golang 的高性能 LLM 语义缓存中间件，旨在通过智能匹配和缓存相似查询，大幅降低大型语言模型（LLM）API 的调用成本并提升响应速度。

### 1.3. 目标用户
- AI 应用开发者 & 架构师
- 数据科学家 & 算法工程师
- 企业技术负责人 (CTO/Tech Lead)

### 1.3. 产品愿景
赋能下一代AI应用，实现极致的效率与成本控制。

---

## 2. 产品概述

### 2.1. 核心价值主张
- **极致性能**: 基于 Golang 的高并发特性，提供卓越的吞吐量和超低延迟。
- **成本效益**: 智能缓存相似查询，大幅削减 LLM API 支出。
- **模型无关**: 兼容主流 LLM 和 Embedding 模型，避免技术栈锁定。
- **部署灵活**: 支持单机、集群及云原生部署，适应各类环境。
- **企业就绪**: 内置监控、持久化、高可用等企业级功能。

### 2.2. 关键使用场景
- **客服机器人**: 缓存常见用户问题，提升响应速度和一致性。
- **RAG 增强的知识库**: 缓存对知识文档的查询，降低检索和生成成本。
- **内容创作辅助**: 缓存相似的指令或草稿，加速内容迭代。
- **代码生成助手**: 缓存常见的代码片段生成请求。

---

## 3. 功能需求

### 3.1. 功能总览 (Epics)
- **E01: 核心缓存逻辑**
- **E02: 可插拔存储层**
- **E03: 可插拔模型层**
- **E04: 高性能 API 服务**
- **E05: 分布式集群能力**
- **E06: 监控与可观测性**
- **E07: 数据管理与安全**

### 3.2. 功能优先级 (P0/P1/P2)
| 功能 ID | 功能描述 | 优先级 | 所属 Epic |
|---|---|---|---|
| **F-001** | 实现基于向量相似度的缓存查询 | P0 | E01 |
| **F-002** | 实现缓存未命中后的异步写入 | P0 | E01 |
| **F-003** | 支持 SQLite 作为本地向量和标量存储 | P0 | E02 |
| **F-004** | 支持通过配置调整相似度阈值 | P0 | E01 |
| **F-005** | 提供 HTTP API 接口用于缓存查询 | P0 | E04 |
| **F-006** | 支持 OpenAI Embedding API | P0 | E03 |
| **F-007** | 支持 LRU/LFU 缓存淘汰策略 | P1 | E01 |
| **F-008** | 支持 Milvus/Weaviate 等生产级向量数据库 | P1 | E02 |
| **F-009** | 支持本地/开源 Embedding 模型 (e.g., ONNX) | P1 | E03 |
| **F-010** | 提供 Prometheus 格式的监控指标 | P1 | E06 |
| **F-011** | 实现基于 Raft 的分布式集群模式 | P2 | E05 |
| **F-012** | 提供数据导入/导出工具 | P2 | E07 |
| **F-013** | 支持基于角色的访问控制 (RBAC) | P2 | E07 |

### 3.3. Epic 详细说明

#### 3.3.1. E01: 核心缓存逻辑
（待补充）

#### 3.3.2. E02: 可插拔存储层

**目标**: 提供灵活、可扩展的存储后端，支持不同场景下的数据持久化和检索需求。

**设计理念**: 借鉴 GPTCache 的三层存储分离架构，将向量数据、标量数据和对象数据进行逻辑分离，并通过统一的接口进行管理。

##### 3.3.2.1. 向量数据存储模块 (Vector Storage)
- **功能**: 负责存储和检索 LLM 查询的 Embedding 向量。
- **技术选型**:
    - **本地开发/测试**: Faiss (in-memory) 或 Hnswlib。
    - **生产环境**: Milvus, Weaviate, Qdrant 等专业向量数据库。
- **关键指标**: 向量检索速度、索引构建效率、存储容量。

##### 3.3.2.2. 标量数据存储模块 (Scalar Storage)
- **功能**: 负责存储 LLM 查询的原始文本、LLM 响应、元数据（如时间戳、LLM 模型信息、相似度阈值等）。
- **技术选型**:
    - **本地开发/测试**: SQLite。
    - **生产环境**: PostgreSQL, MySQL, Redis (作为元数据缓存)。
- **关键指标**: 读写性能、事务支持、数据一致性。

##### 3.3.2.3. 对象数据存储模块 (Object Storage)
- **功能**: 负责存储 LLM 响应中可能包含的大型非结构化数据，例如图像、音频、视频等（当 LLM 支持多模态输出时）。
- **技术选型**:
    - **本地开发/测试**: 本地文件系统。
    - **生产环境**: S3 兼容的对象存储服务（如 AWS S3, MinIO）。
- **关键指标**: 大文件存储和检索效率、成本效益、可扩展性。

#### 3.3.3. E03: 可插拔模型层
（待补充）

#### 3.3.4. E04: 高性能 API 服务
（待补充）

#### 3.3.5. E05: 分布式集群能力
（待补充）

#### 3.3.6. E06: 监控与可观测性
（待补充）

#### 3.3.7. E07: 数据管理与安全
（待补充）
| **F-014** | 实现多轮对话上下文处理机制 | P1 | E01 |
| **F-014** | 实现自定义缓存淘汰策略 | P2 | E01 |
| **F-014** | 提供预设的 Grafana 仪表盘模板 | P1 | E06 |

### 3.3. 核心功能详述

#### 3.3.1. F-004: 相似度阈值调整策略

**功能描述**:
LLM-Cache 允许用户通过配置灵活调整语义相似度匹配的阈值，以平衡缓存命中率、响应准确性和 LLM API 调用成本。不同的业务场景对相似度匹配的严格程度有不同的要求。

**业务规则与逻辑**:
- **阈值范围**: 相似度阈值应支持 0.0 到 1.0 之间的浮点数配置。
    - 1.0 表示严格的精确匹配（或极高相似度）。
    - 0.0 表示最低相似度（几乎不进行过滤）。
- **默认值**: 系统应提供一个合理的默认阈值（例如 0.8），以在大多数通用场景下提供良好的开箱即用体验。
- **配置方式**:
    - **启动配置**: 支持通过配置文件（如 YAML/JSON）或环境变量在服务启动时设置。
    - **运行时调整 (P2)**: 考虑未来支持通过管理 API 或控制台在运行时动态调整阈值，无需重启服务。
- **影响**:
    - **阈值越高**: 缓存命中率可能降低，但缓存结果的准确性更高，更接近原始查询。适用于对准确性要求极高的场景（如法律咨询、金融问答）。
    - **阈值越低**: 缓存命中率可能提高，但可能返回与原始查询语义上不完全匹配的结果。适用于对多样性或成本控制要求更高的场景（如创意内容生成、闲聊机器人）。

**技术实现考量**:
- 阈值将直接应用于向量相似度计算后的得分判断。
- 确保阈值调整的原子性和线程安全，尤其是在支持运行时调整的情况下。

**验收标准**:
- 用户能够通过配置文件成功设置相似度阈值，并观察到缓存命中行为的变化。
- 在不同阈值设置下，系统能够正确地进行语义匹配和缓存决策。
- （如果实现运行时调整）用户能够通过 API 动态调整阈值，且调整立即生效。

### 3.3. 核心功能详述

#### 3.3.1. F-004: 相似度阈值调整策略

**功能描述**:
LLM-Cache 允许用户通过配置灵活调整语义相似度匹配的阈值，以平衡缓存命中率、响应准确性和 LLM API 调用成本。不同的业务场景对相似度匹配的严格程度有不同的要求。

**业务规则与逻辑**:
- **阈值范围**: 相似度阈值应支持 0.0 到 1.0 之间的浮点数配置。
    - 1.0 表示严格的精确匹配（或极高相似度）。
    - 0.0 表示最低相似度（几乎不进行过滤）。
- **默认值**: 系统应提供一个合理的默认阈值（例如 0.8），以在大多数通用场景下提供良好的开箱即用体验。
- **配置方式**:
    - **启动配置**: 支持通过配置文件（如 YAML/JSON）或环境变量在服务启动时设置。
    - **运行时调整 (P2)**: 考虑未来支持通过管理 API 或控制台在运行时动态调整阈值，无需重启服务。
- **影响**:
    - **阈值越高**: 缓存命中率可能降低，但缓存结果的准确性更高，更接近原始查询。适用于对准确性要求极高的场景（如法律咨询、金融问答）。
    - **阈值越低**: 缓存命中率可能提高，但可能返回与原始查询语义上不完全匹配的结果。适用于对多样性或成本控制要求更高的场景（如创意内容生成、闲聊机器人）。

**技术实现考量**:
- 阈值将直接应用于向量相似度计算后的得分判断。
- 确保阈值调整的原子性和线程安全，尤其是在支持运行时调整的情况下。

**验收标准**:
- 用户能够通过配置文件成功设置相似度阈值，并观察到缓存命中行为的变化。
- 在不同阈值设置下，系统能够正确地进行语义匹配和缓存决策。
- （如果实现运行时调整）用户能够通过 API 动态调整阈值，且调整立即生效。

### 3.3. 核心功能详述

#### 3.3.1. F-004: 相似度阈值调整策略

**功能描述**:
LLM-Cache 允许用户通过配置灵活调整语义相似度匹配的阈值，以平衡缓存命中率、响应准确性和 LLM API 调用成本。不同的业务场景对相似度匹配的严格程度有不同的要求。

**业务规则与逻辑**:
- **阈值范围**: 相似度阈值应支持 0.0 到 1.0 之间的浮点数配置。
    - 1.0 表示严格的精确匹配（或极高相似度）。
    - 0.0 表示最低相似度（几乎不进行过滤）。
- **默认值**: 系统应提供一个合理的默认阈值（例如 0.8），以在大多数通用场景下提供良好的开箱即用体验。
- **配置方式**:
    - **启动配置**: 支持通过配置文件（如 YAML/JSON）或环境变量在服务启动时设置。
    - **运行时调整 (P2)**: 考虑未来支持通过管理 API 或控制台在运行时动态调整阈值，无需重启服务。
- **影响**:
    - **阈值越高**: 缓存命中率可能降低，但缓存结果的准确性更高，更接近原始查询。适用于对准确性要求极高的场景（如法律咨询、金融问答）。
    - **阈值越低**: 缓存命中率可能提高，但可能返回与原始查询语义上不完全匹配的结果。适用于对多样性或成本控制要求更高的场景（如创意内容生成、闲聊机器人）。

**技术实现考量**:
- 阈值将直接应用于向量相似度计算后的得分判断。
- 确保阈值调整的原子性和线程安全，尤其是在支持运行时调整的情况下。

**验收标准**:
- 用户能够通过配置文件成功设置相似度阈值，并观察到缓存命中行为的变化。
- 在不同阈值设置下，系统能够正确地进行语义匹配和缓存决策。
- （如果实现运行时调整）用户能够通过 API 动态调整阈值，且调整立即生效。

---

## 4. 非功能性需求

### 4.1. 性能需求
- **吞吐量**: 单节点 QPS > 10,000 (在典型硬件配置下)。
- **延迟**: 缓存命中时，P99 延迟 < 50ms。
- **并发连接**: 单节点支持 > 5,000 并发连接。

### 4.2. 可靠性与可用性
- **服务可用性**: 99.9% (集群模式)。
- **数据可靠性**: 99.99% (当配置持久化存储时)。
- **故障恢复**: 集群模式下，节点故障自动切换，RTO < 30s。

### 4.3. 可扩展性
- **水平扩展**: 支持通过增加节点线性提升系统容量和吞吐量。
- **存储扩展**: 支持对接多种外部存储系统，无缝扩展存储容量。

### 4.4. 安全性
- 支持 API Token 认证。
- 支持 TLS/SSL 加密传输。
- 敏感数据（如 API Keys）需加密存储。

---

## 5. 术语表 (Glossary)

| 术语 | 英文 | 定义 |
|---|---|---|
| 语义缓存 | Semantic Cache | 一种理解查询意图的缓存机制，通过向量相似度匹配相似而非完全相同的请求。 |
| 向量化 | Embedding | 将文本等非结构化数据转换为高维向量的过程，是语义理解的基础。 |
| 向量数据库| Vector Database | 专门用于存储和高效检索高维向量的数据库。 |
| RAG | Retrieval-Augmented Generation | 检索增强生成，一种结合了外部知识库的 LLM 应用模式。 |
| TCO | Total Cost of Ownership | 总拥有成本，衡量 IT 投资的综合成本。 |
| ROI | Return on Investment | 投资回报率，评估投资效益的指标。 |

---

## 6. 未来规划 (Roadmap)

- **Q3 2025**:
    - 完成 P0 功能，发布 MVP 版本。
    - 提供 Docker 镜像和详细的上手文档。
- **Q4 2025**:
    - 完成 P1 功能，发布 v1.0 正式版。
    - 支持主流云厂商的向量数据库。
    - 提供 Kubernetes Helm Chart。
- **2026**:
    - 探索多模态（图像、音频）缓存支持。
    - 研究基于 AI 的智能缓存预热和淘汰策略。
    - 构建可视化管理后台。

---

## 8. 技术方案初步设计

### 8.3. 核心模块设计

#### 8.3.1. 缓存数据结构设计
为了实现极致性能的核心价值，内存中的缓存数据结构选型至关重要。我们将评估以下三种方案：

1.  **原生 `map`**
    - **描述**: `map[string]interface{}` 是 Go 语言最基础的哈希表实现。
    - **优点**: 实现简单，易于理解。
    - **缺点**: **非并发安全**，在多协程环境下直接读写会导致竞态条件。
    - **适用阶段**: 仅适用于早期单线程原型验证，**不会在正式版本中使用**。

2.  **`sync.Map`**
    - **描述**: Go 语言标准库提供的并发安全的哈希表。
    - **优点**: 开箱即用，由官方维护，能有效处理常见的并发读写场景。
    - **缺点**: 在高频写入或读写交织的极端场景下，性能可能不如分片锁机制。其内部实现复杂，性能特征不易预测。
    - **适用阶段**: 可作为 **P0 MVP 版本**的快速实现方案，保证基础的并发安全和稳定性。

3.  **自定义分片结构 (Sharded Map)**
    - **描述**: 借鉴 `godis` 和其他高性能系统的设计，将 key 的哈希空间切分为多个分片（Shard），每个分片由一个独立的 `map` 和一个 `sync.RWMutex` 读写锁保护。
    - **优点**:
        - **显著降低锁竞争**: 请求会被均匀分布到不同分片，锁的粒度变得更细，从而大幅提升并发性能。
        - **可预测的性能**: 结构清晰，性能模型简单，易于调优。
        - **高可扩展性**: 分片数量可配置，能根据 CPU 核心数进行调整，充分利用硬件资源。
    - **缺点**: 实现复杂度高于 `sync.Map`。
    - **适用阶段**: **P1 及后续版本**的最终方案，是实现“极致性能”技术目标的核心保障。

